{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import re\n","import pandas as pd\n","import torch\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n","\n","from pathlib import Path\n","!pip install sacremoses\n","\n","#Powtarzalnośc wyników\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["DATAPATH = Path('../data/processed/Tweety25k-1.csv')"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(20928, 3)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1634610870570438661</td>\n","      <td>@KrystPawlowicz Tam najpierw przetrze szlak Ru...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1634193639109799938</td>\n","      <td>@JachiraKlaudia Kurwa I szmata zawsze I wszędz...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1634199203906830340</td>\n","      <td>„Zorganizowana grupa przestępcza”. Czarzasty w...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1635547952168026112</td>\n","      <td>@MichalSzczerba @WWnioski Mam nadzieję, że bad...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1636046850150088725</td>\n","      <td>@Antysyst @michaldworczyk @AndriyYermak @OlKub...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    id                                               text  \\\n","0  1634610870570438661  @KrystPawlowicz Tam najpierw przetrze szlak Ru...   \n","1  1634193639109799938  @JachiraKlaudia Kurwa I szmata zawsze I wszędz...   \n","2  1634199203906830340  „Zorganizowana grupa przestępcza”. Czarzasty w...   \n","3  1635547952168026112  @MichalSzczerba @WWnioski Mam nadzieję, że bad...   \n","4  1636046850150088725  @Antysyst @michaldworczyk @AndriyYermak @OlKub...   \n","\n","   label  \n","0      0  \n","1      1  \n","2      0  \n","3      0  \n","4      1  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Ładowanie danych\n","df = pd.read_csv(DATAPATH)\n","df = pd.concat([df[df['label'] == \"1\"], df[df['label'] == \"0\"]])\n","df.label = df.label.astype(int)\n","df = df.sample(frac = 1).reset_index(drop=True)\n","\n","\n","print(df.shape)\n","df.head()"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T19:22:03.865591Z","iopub.status.busy":"2023-06-20T19:22:03.864608Z","iopub.status.idle":"2023-06-20T19:22:03.871299Z","shell.execute_reply":"2023-06-20T19:22:03.870184Z","shell.execute_reply.started":"2023-06-20T19:22:03.865551Z"},"trusted":true},"outputs":[],"source":["model_names = {\n","    \"herbert-klej-cased-v1\": {\n","        \"tokenizer\": \"allegro/herbert-klej-cased-tokenizer-v1\", \n","        \"model\": \"allegro/herbert-klej-cased-v1\",\n","    },\n","    \"herbert-base-cased\": {\n","        \"tokenizer\": \"allegro/herbert-base-cased\", \n","        \"model\": \"allegro/herbert-base-cased\",\n","    },\n","    \"herbert-large-cased\": {\n","        \"tokenizer\": \"allegro/herbert-large-cased\", \n","        \"model\": \"allegro/herbert-large-cased\",\n","    },\n","}"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-06-20T19:36:03.690143Z","iopub.status.busy":"2023-06-20T19:36:03.689767Z","iopub.status.idle":"2023-06-20T19:36:20.896922Z","shell.execute_reply":"2023-06-20T19:36:20.895654Z","shell.execute_reply.started":"2023-06-20T19:36:03.690117Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacremoses) (2023.5.5)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from sacremoses) (1.16.0)\n","Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses) (8.1.3)\n","Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from sacremoses) (1.2.0)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sacremoses) (4.64.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=08cf7a7d65982bf7fe8f2eda8284630775d5117dacac05b5c69141c2abecba56\n","  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n","Successfully built sacremoses\n","Installing collected packages: sacremoses\n","Successfully installed sacremoses-0.0.53\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# Preprocessing\n","def preprocess_text(text):\n","    # Usunięcie URL-i\n","    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n","    # Usunięcie wzmianek\n","    text = re.sub(r\"@\\w+\", \"\", text)\n","    # Usunięcie hashtagów\n","    text = re.sub(r\"#\\w+\", \"\", text)\n","    return text\n","\n","df[\"text\"] =df.text.astype(str).apply(preprocess_text)\n","\n","# Podział na zbiór treningowy i testowy\n","train_texts, test_texts, train_labels, test_labels = train_test_split(\n","    df[\"text\"].tolist(), df[\"label\"].tolist(), test_size=0.15, random_state=42\n",")\n","\n","# Tokenizacja\n","tokenizer = AutoTokenizer.from_pretrained(\"allegro/herbert-large-cased\")\n","train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n","test_encodings = tokenizer(test_texts, truncation=True, padding=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Tworzenie zbioru danych\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item[\"labels\"] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_dataset = Dataset(train_encodings, train_labels)\n","test_dataset = Dataset(test_encodings, test_labels)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Inicjalizacja modelu HERBERT\n","model = AutoModelForSequenceClassification.from_pretrained(\"allegro/herbert-large-cased\", num_labels=2)\n","\n","# Trenowanie modelu\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.train()\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n","\n","optimizer = AdamW(model.parameters(), lr=1e-5)\n","num_epochs = 3\n","\n","for epoch in range(num_epochs):\n","    print(epoch)\n","    for idx, batch in enumerate(train_loader):\n","        print(idx)\n","        optimizer.zero_grad()\n","        inputs = {key: val.to(device) for key, val in batch.items()}\n","        outputs = model(**inputs)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","\n","# Ewaluacja modelu\n","model.eval()\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","predictions = []\n","all_labels = []\n","\n","with torch.no_grad():\n","    for batch in test_loader:\n","        inputs = {key: val.to(device) for key, val in batch.items()}\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","        predictions.extend(torch.argmax(logits, dim=1).tolist())\n","        all_labels.extend(inputs[\"labels\"].tolist())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracy = accuracy_score(all_labels, predictions)\n","precision = precision_score(all_labels, predictions)\n","recall = recall_score(all_labels, predictions)\n","f1 = f1_score(all_labels, predictions)\n","auc = roc_auc_score(all_labels, predictions)\n","\n","print(\"Dokładność:\", accuracy)\n","print(\"Swoistość:\", precision)\n","print(\"Czułość:\", recall)\n","print(\"F1 Score:\", f1)\n","print(\"AUC:\", auc)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
